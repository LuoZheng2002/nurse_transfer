{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and arrange features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = r'data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "# drop the \"Index\" column\n",
    "data = data.drop('Index', axis=1)\n",
    "\n",
    "features = data.columns\n",
    "numeric_features = ['Age','Years of Work Experience','Years of Work Experience at Current Institution', 'Institution Level', 'Number of Children Under 12',\n",
    "                    'First Degree', 'Highest Degree', 'Monthly Night Shift Frequency', 'Monthly Take-home Income',\n",
    "                    'Number of Specialist Trainings/Continuing Education Attended', 'Average Number of Clinical Teaching/Training Activities Participated in per Year', \n",
    "                    'Degree of Application of Specialist Skills in Subsequent Clinical Practice']\n",
    "categorical_features = ['Gender', 'Job Title', 'Position', \n",
    "            'Employment Type',  \n",
    "            'Whether Obtained Specialist Qualification Certificate and the Specialist Field',\n",
    "            'Whether Working in a Specialist Nursing Outpatient Clinic', \n",
    "            'Whether Undertaken Research Projects in the Past Three Years', 'Whether Role Stress is High', \n",
    "            'Whether Empathy Level is High', 'Whether Level of Happiness is High', 'Whether Satisfaction with Performance Distribution is High']\n",
    "target = 'In Your Current Medical Institution, Your Inclination to Change Position in the Next 1-10 Years'\n",
    "# ensure numeric_features is a subset of features\n",
    "assert(all(elem in features for elem in numeric_features))\n",
    "# ensure categorical_features is a subset of features\n",
    "assert(all(elem in features for elem in categorical_features))\n",
    "# ensure each feature is either in numeric_features or categorical_features, or it is the target\n",
    "assert(all(elem in numeric_features or elem in categorical_features or elem == target for elem in features))\n",
    "# ensure there is no duplicates among the three categories\n",
    "assert(all(elem not in numeric_features for elem in categorical_features))\n",
    "assert(all(elem not in categorical_features for elem in numeric_features))\n",
    "assert(target not in numeric_features + categorical_features)\n",
    "\n",
    "# X is all but target\n",
    "X = data[numeric_features + categorical_features]\n",
    "y = data[target]\n",
    "\n",
    "# X = X.values\n",
    "# y = y.values\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing procedures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preproc_scale_onehot = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "preproc_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ]\n",
    ")\n",
    "preproc_onehot = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "feature_selection_logistic = SelectFromModel(LogisticRegression(penalty=\"l1\", solver='liblinear'))\n",
    "feature_selection_random_forest = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# cross-validation template, see the code blocks below for usage\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import optuna\n",
    "from optuna import trial as optuna_trial\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# just for intellisense purposes\n",
    "suggest_float = 'suggest_float'\n",
    "suggest_int = 'suggest_int'\n",
    "suggest_categorical = 'suggest_categorical'\n",
    "\n",
    "metric = 'roc_auc'\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "def cross_validate_model(model_class, model_parameters, fit_parameters, n_trials = 100): # [hyperparameter_name, functionname, (function args)\n",
    "    def objective(trial: optuna_trial.Trial):\n",
    "        # print(f\"Running trial {trial.number}\")\n",
    "        try:\n",
    "            # Define the pipeline\n",
    "            adopt_scalar = trial.suggest_categorical('Adopt StandardScalar for numeric features', [True, False])\n",
    "            adopt_onehot = trial.suggest_categorical('Adopt OneHotEncoder for categorical features', [True, False])\n",
    "            adopt_selection = trial.suggest_categorical('Adopt feature selection', ['None', 'LogisticRegression', 'RandomForest'])\n",
    "            adopt_SMOTE = trial.suggest_categorical('Adopt oversampling using SMOTE', [True, False])\n",
    "            # pipeline steps\n",
    "            steps = []\n",
    "            if adopt_scalar and adopt_onehot: steps.append(('onehot_and_scalar', preproc_scale_onehot))\n",
    "            else:\n",
    "                if adopt_scalar:\n",
    "                    assert(not adopt_onehot)\n",
    "                    steps.append(('scalar', preproc_scale))\n",
    "                if adopt_onehot:\n",
    "                    assert(not adopt_scalar)\n",
    "                    steps.append(('onehot', preproc_onehot))\n",
    "            # if adopt_selection: steps.append(('selection', feature_selection))\n",
    "            if adopt_selection == 'LogisticRegression': steps.append(('selection', feature_selection_logistic))\n",
    "            elif adopt_selection == 'RandomForest': steps.append(('selection', feature_selection_random_forest))\n",
    "            if adopt_SMOTE: steps.append(('smote', smote))\n",
    "            model_args = {}\n",
    "            for model_parameter in model_parameters:\n",
    "                parameter_name, function_name, function_args = model_parameter\n",
    "                func = getattr(trial, function_name)\n",
    "                function_kwargs = {'log': True} if function_name == suggest_float else {}\n",
    "                if function_args[0] == \"hidden_layer_sizes\":\n",
    "                    # transform a scalar to a length 1 tuple for the hidden_layer_sizes parameter for MLPClassifier\n",
    "                    model_args.update({parameter_name: (func(*function_args, **function_kwargs),)})\n",
    "                else:\n",
    "                    model_args.update({parameter_name: func(*function_args, **function_kwargs)})\n",
    "            \n",
    "            fit_args = {}\n",
    "            for fit_parameter in fit_parameters:\n",
    "                parameter_name, function_name, function_args = fit_parameter\n",
    "                func = getattr(trial, function_name)\n",
    "                function_kwargs = {'log': True} if function_name == suggest_float else {}\n",
    "                fit_args.update({'classifier__' + parameter_name: func(*function_args, **function_kwargs)})\n",
    "            model = model_class(**model_args)   \n",
    "            # model._estimator_type = \"classifier\"\n",
    "            # print(model._estimator_type)\n",
    "            \n",
    "            to_numpy = FunctionTransformer(lambda x: x.values if hasattr(x, \"values\") else x, validate=False)\n",
    "            steps.append(('to_numpy', to_numpy))\n",
    "\n",
    "            steps.append(('classifier', model))\n",
    "            \n",
    "            pipeline = ImbPipeline(steps=steps)\n",
    "            # print(pipeline.predict_proba(X_train[:5]))  # should return probabilities\n",
    "            # print(hasattr(pipeline, 'predict_proba'))  # should be True\n",
    "            # Perform cross-validation\n",
    "            # score = cross_val_score(pipeline, X_train, y_train, n_jobs=-1, cv=10, scoring=metric)\n",
    "            score = cross_val_score(pipeline, X_train, y_train, cv=10, scoring=metric, params=fit_args, n_jobs=-1)\n",
    "            mean_score = score.mean()\n",
    "            return mean_score\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler(seed=42))\n",
    "    # print(f\"Total trials: {len(study.trials)}\")\n",
    "    # print(f\"Completed trials: {len([t for t in study.trials if t.state.name == 'COMPLETE'])}\")\n",
    "    # print(f\"Failed trials: {len([t for t in study.trials if t.state.name == 'FAIL'])}\")\n",
    "\n",
    "    # study.optimize(objective, n_trials=n_trials, show_progress_bar=True, n_jobs=-1)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True, catch=(Exception,))\n",
    "\n",
    "    trial = study.best_trial\n",
    "    print(f'{model_class.__name__} Cross-Validation Performance:')\n",
    "    print(\"Best trial:\")\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Best hyperparameters:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plays a sound effect when the task is finished so that we can get notified\n",
    "import os\n",
    "def play_finished_hint():\n",
    "    os.system('powershell.exe -c \"(New-Object Media.SoundPlayer \\\\\"C:\\\\\\\\Windows\\\\\\\\Media\\\\\\\\ok.wav\\\\\").PlaySync()\"')\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.utils._tags import InputTags\n",
    "class SklearnCompatibleTabNetClassifier(BaseEstimator, ClassifierMixin):\n",
    "    # _estimator_type = \"classifier\"  # Tells scikit-learn it's a classifier\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.tabnet = TabNetClassifier(**kwargs)\n",
    "\n",
    "    def __sklearn_tags__(self):\n",
    "        class DummyTag:\n",
    "            def __init__(self):\n",
    "                self.estimator_type = 'classifier'\n",
    "                self.input_tags=InputTags(one_d_array=False, two_d_array=True, three_d_array=False, sparse=True, categorical=False, string=False, dict=False, positive_only=False, allow_nan=False, pairwise=False)\n",
    "                self.requires_fit=True\n",
    "        return DummyTag()\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        # self.tabnet.fit(X, y)\n",
    "        # print(\"model.fit called\")\n",
    "        self.tabnet.fit(\n",
    "            X, y, \n",
    "            **fit_params\n",
    "        )\n",
    "        self.classes_ = np.unique(y)  # required by scikit-learn\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.tabnet.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.tabnet.predict_proba(X)\n",
    "\n",
    "    # def score(self, X, y):\n",
    "    #     from sklearn.metrics import accuracy_score\n",
    "    #     return accuracy_score(y, self.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "Best trial: 0. Best value: 0.627615:  20%|██        | 1/5 [00:47<03:09, 47.50s/it]c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "Best trial: 0. Best value: 0.627615:  40%|████      | 2/5 [01:15<01:47, 35.85s/it]c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "Best trial: 0. Best value: 0.627615:  60%|██████    | 3/5 [01:41<01:02, 31.35s/it]c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "Best trial: 3. Best value: 0.672114:  80%|████████  | 4/5 [02:08<00:29, 29.95s/it]c:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "Best trial: 3. Best value: 0.672114: 100%|██████████| 5/5 [02:32<00:00, 30.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SklearnCompatibleTabNetClassifier Cross-Validation Performance:\n",
      "Best trial:\n",
      "  Value: 0.6721144636015326\n",
      "  Best hyperparameters:\n",
      "    Adopt StandardScalar for numeric features: True\n",
      "    Adopt OneHotEncoder for categorical features: True\n",
      "    Adopt feature selection: None\n",
      "    Adopt oversampling using SMOTE: True\n",
      "    n_d: 4\n",
      "    n_a: 4\n",
      "    n_steps: 3\n",
      "    gamma: 1.0827068114640508\n",
      "    lambda_sparse: 0.00011097554561103102\n",
      "    momentum: 0.042301944043371176\n",
      "    clip_value: 1.3091925426230433\n",
      "    scheduler_params: None\n",
      "    verbose: 0\n",
      "    device_name: cuda\n",
      "    batch_size: 20\n",
      "    virtual_batch_size: 15\n",
      "    max_epochs: 7\n"
     ]
    }
   ],
   "source": [
    "# Example hyperparameter suggestions for TabNetClassifier\n",
    "model_parameters = [\n",
    "    # ('n_d', suggest_categorical, ['n_d', [8, 12, 16]]),\n",
    "    # ('n_a', suggest_categorical, ['n_a', [8, 12, 16]]),\n",
    "    ('n_d', suggest_categorical, ['n_d', [4]]),\n",
    "    ('n_a', suggest_categorical, ['n_a', [4]]),\n",
    "    ('n_steps', suggest_categorical, ['n_steps', [3]]),\n",
    "    ('gamma', suggest_float, ['gamma', 1.0, 1.5]),\n",
    "    ('lambda_sparse', suggest_float, ['lambda_sparse', 1e-4, 1e-3]),\n",
    "    ('momentum', suggest_float, ['momentum', 0.02, 0.2]),\n",
    "    ('clip_value', suggest_float, ['clip_value', 1.0, 2.0]),\n",
    "    ('scheduler_params', suggest_categorical, ['scheduler_params', [None]]),\n",
    "    ('verbose', suggest_categorical, ['verbose', [0]]),\n",
    "    ('device_name', suggest_categorical, ['device_name', ['cuda']]),  # use 'cuda' if GPU is available,\n",
    "]\n",
    "fit_parameters = [\n",
    "    ('batch_size', suggest_int, ['batch_size', 16, 32]),\n",
    "    \n",
    "    ('virtual_batch_size', suggest_int, ['virtual_batch_size', 8, 16]),\n",
    "    ('max_epochs', suggest_int, ['max_epochs', 5, 10]),\n",
    "]\n",
    "\n",
    "cross_validate_model(SklearnCompatibleTabNetClassifier, model_parameters, fit_parameters, 5)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 20. Best value: 0.708142:  36%|███▌      | 36/100 [01:24<02:29,  2.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      3\u001b[39m model_parameters=[\u001b[38;5;66;03m# [hyperparameter_name, functionname, (function args)\u001b[39;00m\n\u001b[32m      4\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, suggest_int, [\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m1000\u001b[39m]),\n\u001b[32m      5\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, suggest_int, [\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m30\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m'\u001b[39m, suggest_categorical, [\u001b[33m'\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m'\u001b[39m, [\u001b[32m42\u001b[39m]])\n\u001b[32m     10\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcross_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m play_finished_hint()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mcross_validate_model\u001b[39m\u001b[34m(model_class, model_parameters, fit_parameters, n_trials)\u001b[39m\n\u001b[32m     81\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, sampler=optuna.samplers.RandomSampler(seed=\u001b[32m42\u001b[39m))\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# print(f\"Total trials: {len(study.trials)}\")\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# print(f\"Completed trials: {len([t for t in study.trials if t.state.name == 'COMPLETE'])}\")\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# print(f\"Failed trials: {len([t for t in study.trials if t.state.name == 'FAIL'])}\")\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# study.optimize(objective, n_trials=n_trials, show_progress_bar=True, n_jobs=-1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mException\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m trial = study.best_trial\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Cross-Validation Performance:\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mcross_validate_model.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     69\u001b[39m pipeline = ImbPipeline(steps=steps)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# print(pipeline.predict_proba(X_train[:5]))  # should return probabilities\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# print(hasattr(pipeline, 'predict_proba'))  # should be True\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# score = cross_val_score(pipeline, X_train, y_train, n_jobs=-1, cv=10, scoring=metric)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m score = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m mean_score = score.mean()\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mean_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luo20\\New Volume D\\Desktop\\nurse_transfer\\venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier cross-validation task\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('n_estimators', suggest_int, ['n_estimators', 10, 1000]),\n",
    "    ('max_depth', suggest_int, ['max_depth', 1, 30]),\n",
    "    ('min_samples_split', suggest_int, ['min_samples_split', 2, 20]),\n",
    "    ('min_samples_leaf', suggest_int, ['min_samples_leaf', 1, 10]),\n",
    "    ('max_features', suggest_categorical, ['max_features', ['log2', 'sqrt']]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]])\n",
    "]\n",
    "cross_validate_model(RandomForestClassifier, model_parameters, dict(), 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost cross-validation task\n",
    "import xgboost as xgb\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('n_estimators', suggest_int, ['n_estimators', 50, 1000]),\n",
    "    ('max_depth', suggest_int, ['max_depth', 3, 20]),\n",
    "    ('learning_rate', suggest_float, ['learning_rate', 0.005, 0.2]),\n",
    "    ('subsample', suggest_float, ['subsample', 0.5, 1.0]),\n",
    "    ('colsample_bytree', suggest_float, ['colsample_bytree', 0.3, 1.0]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]])\n",
    "]\n",
    "cross_validate_model(xgb.XGBClassifier, model_parameters, 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPClassifier cross-validation task\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('hidden_layer_sizes', suggest_categorical, ['hidden_layer_sizes', [200, 100, 50, 20, 5]]),\n",
    "    ('activation', suggest_categorical, ['activation', ['identity', 'logistic', 'tanh', 'relu']]),\n",
    "    ('solver', suggest_categorical, ['solver', ['lbfgs', 'sgd', 'adam']]),\n",
    "    ('alpha', suggest_float, ['alpha', 0.0001, 0.01]),\n",
    "    ('learning_rate', suggest_categorical, ['learning_rate',['constant', 'invscaling', 'adaptive']]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]]),\n",
    "    ('max_iter', suggest_int, ['max_iter', 100, 200])\n",
    "]\n",
    "cross_validate_model(MLPClassifier, model_parameters, 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMClassifier cross-validation task\n",
    "import lightgbm as lgb\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('n_estimators', suggest_int, ['n_estimators', 20, 1000]),\n",
    "    ('learning_rate', suggest_float, ['learning_rate', 0.01, 0.2]),\n",
    "    ('num_leaves', suggest_int, ['num_leaves', 31, 100]),\n",
    "    ('max_depth', suggest_int, ['max_depth', 2, 20]),\n",
    "    ('min_data_in_leaf', suggest_int, ['min_data_in_leaf', 1, 50]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]])\n",
    "]\n",
    "cross_validate_model(lgb.LGBMClassifier, model_parameters, 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier cross-validation task\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('n_estimators', suggest_int, ['n_estimators', 50, 500]),\n",
    "    ('learning_rate', suggest_float, ['learning_rate', 0.01, 1.0]),\n",
    "    ('algorithm', suggest_categorical, ['algorithm', ['SAMME']]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]]),\n",
    "]\n",
    "cross_validate_model(AdaBoostClassifier, model_parameters, 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostClassifier cross-validation task\n",
    "from catboost import CatBoostClassifier\n",
    "model_parameters=[# [hyperparameter_name, functionname, (function args)\n",
    "    ('iterations', suggest_int, ['iterations', 50, 200]),\n",
    "    ('learning_rate', suggest_float, ['learning_rate', 0.01, 0.2]),\n",
    "    ('depth', suggest_int, ['depth', 4, 8]),\n",
    "    ('l2_leaf_reg', suggest_int, ['l2_leaf_reg', 1, 10]),\n",
    "    ('early_stopping_rounds', suggest_int, ['early_stopping_rounds', 5, 20]),\n",
    "    ('verbose', suggest_categorical, ['verbose', [0]]),\n",
    "    ('random_state', suggest_categorical, ['random_state', [42]])\n",
    "]\n",
    "cross_validate_model(CatBoostClassifier, model_parameters, 100)\n",
    "play_finished_hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the model based on the best model and best hyperparameters\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# MLPClassifier has the best performance in the cross-validation section\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=50,\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    alpha=0.0031553241961207877,\n",
    "    learning_rate='constant',\n",
    "    random_state=42,\n",
    "    max_iter=102\n",
    ")\n",
    "# adopts one-hot encoder and SMOTE\n",
    "preproc_onehot = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),  # Numerical features first\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "feature_selection = SelectFromModel(LogisticRegression(penalty=\"l1\", solver='liblinear', random_state=42))\n",
    "smote = SMOTE(random_state=42)\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('onehot', preproc_onehot)\n",
    "])\n",
    "\n",
    "\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train, y_train)\n",
    "X_train_smoted, y_train_smoted = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "clf.fit(X_train_smoted, y_train_smoted)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test_transformed)[:,1]\n",
    "\n",
    "encoder = pipeline.named_steps['onehot'].named_transformers_['cat']\n",
    "one_hot_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "# Combine original and one-hot feature names\n",
    "all_feature_names = numeric_features + list(one_hot_feature_names)\n",
    "# make sure the one-hot-transformed feature name dimesion matches all_feature_names\n",
    "X_onehot = preproc_onehot.fit_transform(X_train)\n",
    "assert(X_onehot.shape[1] == len(all_feature_names))\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Convert probabilities to binary predictions (using 0.5 as threshold)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate Sensitivity (Recall)\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "# Calculate Youden's J Score\n",
    "youden_j = sensitivity + specificity - 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"Youden's J Score: {youden_j:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "# Use the optimal preprocessing procedures (no feature selection, resample with SMOTE)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "# Step 6: Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba):.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # Diagonal line for random guessing\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP plots\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "\n",
    "X_train_sampled = shap.sample(X_train_preprocessed, 10)\n",
    "explainer = shap.KernelExplainer(clf.predict_proba, X_train_sampled, feature_names=all_feature_names)\n",
    "\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test_preprocessed)\n",
    "\n",
    "explanation = shap.Explanation(values=shap_values[:,:,1], \n",
    "                                base_values=explainer.expected_value[1], \n",
    "                                data=X_test_preprocessed, \n",
    "                                feature_names=all_feature_names)\n",
    "shap.plots.violin(explanation, max_display=15)\n",
    "shap.plots.bar(explanation, max_display=15)\n",
    "shap.plots.waterfall(explanation[0], max_display=15)\n",
    "shap.plots.waterfall(explanation[1], max_display=15)\n",
    "shap.plots.waterfall(explanation[2], max_display=15)\n",
    "shap.plots.waterfall(explanation[3], max_display=15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
